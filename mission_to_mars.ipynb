{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2352d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: splinter[selenium4] in /Users/user/miniforge3/lib/python3.9/site-packages (0.18.1)\n",
      "Collecting selenium<5.0,>=4.1.0\n",
      "  Downloading selenium-4.4.3-py3-none-any.whl (985 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m986.0/986.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: urllib3[socks]~=1.26 in /Users/user/miniforge3/lib/python3.9/site-packages (from selenium<5.0,>=4.1.0->splinter[selenium4]) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /Users/user/miniforge3/lib/python3.9/site-packages (from selenium<5.0,>=4.1.0->splinter[selenium4]) (2022.6.15)\n",
      "Collecting trio~=0.17\n",
      "  Downloading trio-0.21.0-py3-none-any.whl (358 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m359.0/359.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting trio-websocket~=0.9\n",
      "  Using cached trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /Users/user/miniforge3/lib/python3.9/site-packages (from trio~=0.17->selenium<5.0,>=4.1.0->splinter[selenium4]) (22.1.0)\n",
      "Collecting sortedcontainers\n",
      "  Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Collecting outcome\n",
      "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting sniffio\n",
      "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Collecting async-generator>=1.9\n",
      "  Using cached async_generator-1.10-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: idna in /Users/user/miniforge3/lib/python3.9/site-packages (from trio~=0.17->selenium<5.0,>=4.1.0->splinter[selenium4]) (3.3)\n",
      "Collecting wsproto>=0.14\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /Users/user/miniforge3/lib/python3.9/site-packages (from urllib3[socks]~=1.26->selenium<5.0,>=4.1.0->splinter[selenium4]) (1.7.1)\n",
      "Collecting h11<1,>=0.9.0\n",
      "  Using cached h11-0.13.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: sortedcontainers, sniffio, outcome, h11, async-generator, wsproto, trio, trio-websocket, selenium\n",
      "  Attempting uninstall: selenium\n",
      "    Found existing installation: selenium 3.141.0\n",
      "    Uninstalling selenium-3.141.0:\n",
      "      Successfully uninstalled selenium-3.141.0\n",
      "Successfully installed async-generator-1.10 h11-0.13.0 outcome-1.2.0 selenium-4.4.3 sniffio-1.3.0 sortedcontainers-2.4.0 trio-0.21.0 trio-websocket-0.9.2 wsproto-1.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install splinter[selenium4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e85dbe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting webdriver-manager\n",
      "  Downloading webdriver_manager-3.8.3-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: requests in /Users/user/miniforge3/lib/python3.9/site-packages (from webdriver-manager) (2.28.1)\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-0.21.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: tqdm in /Users/user/miniforge3/lib/python3.9/site-packages (from webdriver-manager) (4.64.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/user/miniforge3/lib/python3.9/site-packages (from requests->webdriver-manager) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/user/miniforge3/lib/python3.9/site-packages (from requests->webdriver-manager) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/user/miniforge3/lib/python3.9/site-packages (from requests->webdriver-manager) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/user/miniforge3/lib/python3.9/site-packages (from requests->webdriver-manager) (1.26.11)\n",
      "Installing collected packages: python-dotenv, webdriver-manager\n",
      "Successfully installed python-dotenv-0.21.0 webdriver-manager-3.8.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a70aa63d",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup \n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92a37afe",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c2b9b9b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/user/Documents/GitHub/web-scraping-challenge'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5230620",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77b4d910",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# setting up splinter\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "\n",
    "# visiting the homepage\n",
    "url = 'https://redplanetscience.com/'\n",
    "browser.visit(url)\n",
    "\n",
    "headlines = []\n",
    "\n",
    "# scrapping the data\n",
    "for x in range(0, 15):\n",
    "    time.sleep(1)\n",
    "\n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup (html, 'html.parser')\n",
    "\n",
    "    results = {}\n",
    "\n",
    "\n",
    "    titles = soup.findAll(name ='div', attrs=\"content_title\" )\n",
    "    #for title in titles:\n",
    "        #print(title.text)\n",
    "\n",
    "    results['titles']= browser.find_by_css(\"div.content_title\")[x].text\n",
    "    results['teaser'] = browser.find_by_css(\"div.article_teaser_body\")[x].text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #for headline, teaser_text in zip (headline_titles, teaser_paragraph):\n",
    "       # results['titles'] = headline.text\n",
    "       # results['teaser'] = teaser_text.text\n",
    "\n",
    "    headlines.append(results)\n",
    "    time.sleep(2)\n",
    "\n",
    "    #browser.quit()\n",
    "\n",
    "        #print('page:', x, '--------------------------------------')\n",
    "        #print(headline.text)\n",
    "        #print(\"\")\n",
    "        #print( teaser_text.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44b0fcdc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'titles': \"Newfound Martian Aurora Actually the Most Common; Sheds Light on Mars' Changing Climate\",\n",
       "  'teaser': 'A type of Martian aurora first identified by NASA’s MAVEN spacecraft in 2016 is actually the most common form of aurora occurring on the Red Planet, according to new results from the mission.'},\n",
       " {'titles': \"How NASA's Perseverance Mars Team Adjusted to Work in the Time of Coronavirus\",\n",
       "  'teaser': 'Like much of the rest of the world, the Mars rover team is pushing forward with its mission-critical work while putting the health and safety of their colleagues and community first.'},\n",
       " {'titles': 'Mars 2020 Stands on Its Own Six Wheels',\n",
       "  'teaser': \"In time-lapse video, taken at JPL, captures the first time NASA's Mars 2020 rover carries its full weight on its legs and wheels.\"},\n",
       " {'titles': 'MOXIE Could Help Future Rockets Launch Off Mars',\n",
       "  'teaser': \"NASA's Perseverance rover carries a device to convert Martian air into oxygen that, if produced on a larger scale, could be used not just for breathing, but also for fuel.\"},\n",
       " {'titles': 'NASA Moves Forward With Campaign to Return Mars Samples to Earth',\n",
       "  'teaser': 'During this next phase, the program will mature critical technologies and make critical design decisions as well as assess industry partnerships.'},\n",
       " {'titles': \"NASA's Perseverance Rover Will Peer Beneath Mars' Surface\",\n",
       "  'teaser': \"The agency's newest rover will use the first ground-penetrating radar instrument on the Martian surface to help search for signs of past microbial life.\"},\n",
       " {'titles': \"NASA's MAVEN Observes Martian Night Sky Pulsing in Ultraviolet Light\",\n",
       "  'teaser': 'Vast areas of the Martian night sky pulse in ultraviolet light, according to images from NASA’s MAVEN spacecraft. The results are being used to illuminate complex circulation patterns in the Martian atmosphere.'},\n",
       " {'titles': \"NASA's MAVEN Explores Mars to Understand Radio Interference at Earth\",\n",
       "  'teaser': 'NASA’s MAVEN spacecraft has discovered “layers” and “rifts” in the electrically charged part of the upper atmosphere of Mars.'},\n",
       " {'titles': 'NASA Perseverance Mars Rover Scientists Train in the Nevada Desert',\n",
       "  'teaser': \"Team members searched for signs of ancient microscopic life there, just as NASA's latest rover will on the Red Planet next year.\"},\n",
       " {'titles': 'MAVEN Maps Electric Currents around Mars that are Fundamental to Atmospheric Loss',\n",
       "  'teaser': 'Five years after NASA’s MAVEN spacecraft entered into orbit around Mars, data from the mission has led to the creation of a map of electric current systems in the Martian atmosphere.'},\n",
       " {'titles': \"A Martian Roundtrip: NASA's Perseverance Rover Sample Tubes\",\n",
       "  'teaser': \"Marvels of engineering, the rover's sample tubes must be tough enough to safely bring Red Planet samples on the long journey back to Earth in immaculate condition.\"},\n",
       " {'titles': 'My Culture, My Voice',\n",
       "  'teaser': 'In honor of Hispanic Heritage Month, Christina Hernandez, an instrument engineer on the Mars 2020 mission, talks about her childhood and journey to NASA.'},\n",
       " {'titles': \"A Year of Surprising Science From NASA's InSight Mars Mission\",\n",
       "  'teaser': \"A batch of new papers summarizes the lander's findings above and below the surface of the Red Planet.\"},\n",
       " {'titles': 'Global Storms on Mars Launch Dust Towers Into the Sky',\n",
       "  'teaser': 'A Mars Dust Tower Stands Out Dust storms are common on Mars. But every decade or so, something unpredictable happens: a series of runaway storms break out, covering the entire planet in a dusty haze.'},\n",
       " {'titles': 'Independent Review Indicates NASA Prepared for Mars Sample Return Campaign',\n",
       "  'teaser': 'NASA released an independent review report Tuesday indicating the agency is well positioned for its Mars Sample Return campaign to bring pristine samples from Mars to Earth for scientific study.'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503307cd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9850bbd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://spaceimages-mars.com/image/featured/mars3.jpg\n"
     ]
    }
   ],
   "source": [
    "    url = 'https://spaceimages-mars.com/'\n",
    "    browser.visit(url)\n",
    "\n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    featured_image_link = url + soup.find('img', class_=\"headerimage\")[\"src\"]\n",
    "\n",
    "    print(featured_image_link )\n",
    "    #featured_image_url = url + featured_image_link['src']\n",
    "\n",
    "    #print(featured_image_link[\"src\"])\n",
    "\n",
    "    #print(featured_image_url[\"src\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2f9095",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7e0b572",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/miniforge3/lib/python3.9/site-packages/pandas/core/internals/construction.py:576: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  values = np.array([convert(v) for v in values])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'listings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#### removing unwanted newlines to clean up the table.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#mars_planet_profile_html.replace('\\n', '')\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#show table\u001b[39;00m\n\u001b[1;32m     16\u001b[0m mars_planet_profile_html\n\u001b[0;32m---> 18\u001b[0m \u001b[43mlistings\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmars_table\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m=\u001b[39m mars_planet_profile_html\n",
      "\u001b[0;31mNameError\u001b[0m: name 'listings' is not defined"
     ]
    }
   ],
   "source": [
    "#url for reading the SS table with state names and abbreviations\n",
    "url = \"https://galaxyfacts-mars.com/\"\n",
    "\n",
    "facts_about_mars =pd.read_html(url)\n",
    "\n",
    "\n",
    "mars_facts_df = pd.DataFrame(facts_about_mars)\n",
    "\n",
    "## DataFrames as HTML\n",
    "mars_planet_profile_html = mars_facts_df.to_html()\n",
    "\n",
    "#### removing unwanted newlines to clean up the table.\n",
    "#mars_planet_profile_html.replace('\\n', '')\n",
    "\n",
    "#show table\n",
    "mars_planet_profile_html\n",
    "\n",
    "listings[\"mars_table\"]= mars_planet_profile_html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ba3fd6",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "-------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f39758e4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'Cerberus Hemisphere Enhanced', 'img_url': 'https://marshemispheres.com/images/cerberus_enhanced.tif'}, {'title': 'Schiaparelli Hemisphere Enhanced', 'img_url': 'https://marshemispheres.com/images/schiaparelli_enhanced.tif'}, {'title': 'Syrtis Major Hemisphere Enhanced', 'img_url': 'https://marshemispheres.com/images/syrtis_major_enhanced.tif'}, {'title': 'Valles Marineris Hemisphere Enhanced', 'img_url': 'https://marshemispheres.com/images/valles_marineris_enhanced.tif'}]\n"
     ]
    }
   ],
   "source": [
    " #set up splinter\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "\n",
    "\n",
    "# go to the website\n",
    "url = 'https://marshemispheres.com/'\n",
    "browser.visit(url)\n",
    "\n",
    "\n",
    "# grabbing all links to the images on homepage\n",
    "links = browser.find_by_css(\"a.product-item img\")\n",
    "\n",
    "img_urls = []\n",
    "\n",
    "\n",
    "# finding the the title and link of every image\n",
    "for i in range(len(links)):\n",
    "    results = {}\n",
    "\n",
    "    browser.find_by_css(\"a.product-item img\")[i].click()\n",
    "    #link.click()\n",
    "    time.sleep(1)\n",
    "# appending the scrapped data to the results dictionary    \n",
    "    element = browser.links.find_by_text(\"Original\").first\n",
    "    results[\"title\"] = browser.find_by_css(\"h2.title\").text\n",
    "    results[\"img_url\"] = element[\"href\"]\n",
    "\n",
    "\n",
    "# appening the results dictionary into the img_urls list    \n",
    "    img_urls.append(results)\n",
    "    browser.back()\n",
    "    time.sleep(1)\n",
    "# close the browser\n",
    "    #browser.quit()\n",
    "print(img_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec18efa0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Valles Marineris Hemisphere Enhanced',\n",
       " 'img_url': 'https://marshemispheres.com/images/valles_marineris_enhanced.tif'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aaf9dd61",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Cerberus Hemisphere Enhanced',\n",
       "  'img_url': 'images/39d3266553462198bd2fbc4d18fbed17_cerberus_enhanced.tif_thumb.png'},\n",
       " {'title': 'Schiaparelli Hemisphere Enhanced',\n",
       "  'img_url': 'images/08eac6e22c07fb1fe72223a79252de20_schiaparelli_enhanced.tif_thumb.png'},\n",
       " {'title': 'Syrtis Major Hemisphere Enhanced',\n",
       "  'img_url': 'images/55a0a1e2796313fdeafb17c35925e8ac_syrtis_major_enhanced.tif_thumb.png'},\n",
       " {'title': 'Valles Marineris Hemisphere Enhanced',\n",
       "  'img_url': 'images/4e59980c1c57f89c680c0e1ccabbeff1_valles_marineris_enhanced.tif_thumb.png'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return all the HTML on our page\n",
    "html = browser.html\n",
    "\n",
    "# Create Beautiful Soup object, pass in our html and parse with html.parser'\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "\n",
    "# Obtain high-resolution images for each hemisphere of Mars from 'https://marshemispheres.com/'\n",
    "\n",
    "# The url we want to scrape\n",
    "url_hemi = 'https://marshemispheres.com/'\n",
    "\n",
    "# Call visit on our browser and pass the url we want to scrape\n",
    "browser.visit(url_hemi)\n",
    "\n",
    "\n",
    "\n",
    "results = soup.find_all('div', class_='item')\n",
    "\n",
    "# Create empty list for hemisphere title and image results\n",
    "hemisphere_image_urls=[]\n",
    "\n",
    "# Retrieve each list item\n",
    "\n",
    "for result in results:\n",
    "    title = result.find('h3').get_text()\n",
    "    img_url = result.find('img', class_='thumb')['src']\n",
    "    hemisphere_image_urls.append({'title': title,'img_url':img_url})\n",
    "# Print Result\n",
    "hemisphere_image_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86962634",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/miniforge3/lib/python3.9/site-packages/pandas/core/internals/construction.py:576: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  values = np.array([convert(v) for v in values])\n"
     ]
    }
   ],
   "source": [
    "# Setup splinter\n",
    "# browser = init_browser()\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "\n",
    "# Set an empty dict for listings that we can save to Mongo\n",
    "listings = {}\n",
    "\n",
    "# The url we want to scrape\n",
    "url = \"https://marshemispheres.com/\"\n",
    "\n",
    "# Call visit on our browser and pass in the URL we want to scrape   \n",
    "browser.visit(url)\n",
    "\n",
    "# Let it sleep for 1 second\n",
    "time.sleep(1)\n",
    "\n",
    "# Return all the HTML on our page\n",
    "html = browser.html\n",
    "\n",
    "######################################################################\n",
    "url = 'https://spaceimages-mars.com/'\n",
    "browser.visit(url)\n",
    "\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "featured_image_link = url + soup.find('img', class_=\"headerimage\")[\"src\"]\n",
    "\n",
    "listings['featured_image'] = featured_image_link\n",
    "######################################################################\n",
    "######################################################################\n",
    "# url for reading the SS table with state names and abbreviations\n",
    "# url for reading the SS table with state names and abbreviations\n",
    "url = \"https://galaxyfacts-mars.com/\"\n",
    "\n",
    "facts_about_mars = pd.read_html(url)\n",
    "\n",
    "mars_facts_df = pd.DataFrame(facts_about_mars)\n",
    "\n",
    "## DataFrames as HTML\n",
    "mars_planet_profile_html = mars_facts_df.to_html()\n",
    "\n",
    "#### removing unwanted newlines to clean up the table.\n",
    "mars_planet_profile_html.replace('\\n', '')\n",
    "\n",
    "# show table\n",
    "mars_planet_profile_html\n",
    "\n",
    "listings[\"mars_table\"] = mars_planet_profile_html\n",
    "######################################################################\n",
    "\n",
    "######################################################################\n",
    "# grabbing all links to the images on homepage\n",
    "links = browser.find_by_css(\"a.product-item img\")\n",
    "\n",
    "# Create a Beautiful Soup object, pass in our HTML, and call 'html.parser'\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# finding the the title and link of every image\n",
    "for i in range(len(links)):\n",
    "    results = {}\n",
    "\n",
    "    browser.find_by_css(\"a.product-item img\")[i].click()\n",
    "    # link.click()\n",
    "    time.sleep(1)\n",
    "    # appending the scrapped data to the results dictionary\n",
    "    element = browser.links.find_by_text(\"Original\").first\n",
    "    listings[\"title\"] = browser.find_by_css(\"h2.title\").text\n",
    "    listings[\"img_url\"] = element[\"href\"]\n",
    "\n",
    "    # appening the results dictionary into the img_urls list\n",
    "    #listings.append(results)\n",
    "    browser.back()\n",
    "    time.sleep(1)\n",
    "\n",
    "# Build our dictionary for the headline, price, and neighborhood from our scraped data\n",
    "\n",
    "# Quit the browser\n",
    "#browser.quit()\n",
    "\n",
    "# Return our dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6b61f27",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'featured_image': 'https://spaceimages-mars.com/image/featured/mars3.jpg',\n",
       " 'mars_table': '<table border=\"1\" class=\"dataframe\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th></th>\\n      <th>0</th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <th>0</th>\\n      <td>0                1                2\\n0  Mars - Earth Comparison             Mars            Earth\\n1                Diameter:         6,779 km        12,742 km\\n2                    Mass:  6.39 × 10^23 kg  5.97 × 10^24 kg\\n3                   Moons:                2                1\\n4       Distance from Sun:   227,943,824 km   149,598,262 km\\n5          Length of Year:   687 Earth days      365.24 days\\n6             Temperature:     -87 to -5 °C      -88 to 58°C</td>\\n    </tr>\\n    <tr>\\n      <th>1</th>\\n      <td>0                              1\\n0  Equatorial Diameter:                       6,792 km\\n1       Polar Diameter:                       6,752 km\\n2                 Mass:  6.39 × 10^23 kg (0.11 Earths)\\n3                Moons:          2 ( Phobos &amp; Deimos )\\n4       Orbit Distance:       227,943,824 km (1.38 AU)\\n5         Orbit Period:           687 days (1.9 years)\\n6  Surface Temperature:                   -87 to -5 °C\\n7         First Record:              2nd millennium BC\\n8          Recorded By:           Egyptian astronomers</td>\\n    </tr>\\n  </tbody>\\n</table>'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e21c634f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/miniforge3/lib/python3.9/site-packages/pandas/core/internals/construction.py:576: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  values = np.array([convert(v) for v in values])\n"
     ]
    }
   ],
   "source": [
    "# Automates browser actions\n",
    "from splinter import Browser\n",
    "\n",
    "# Parses the HTML\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "# For scraping with Chrome\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from flask import jsonify\n",
    "\n",
    "\n",
    "\n",
    "# Setup splinter\n",
    "# browser = init_browser()\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "\n",
    "# Set an empty dict for listings that we can save to Mongo\n",
    "listings = {}\n",
    "\n",
    "# The url we want to scrape\n",
    "url = \"https://marshemispheres.com/\"\n",
    "\n",
    "# Call visit on our browser and pass in the URL we want to scrape   \n",
    "browser.visit(url)\n",
    "\n",
    "# Let it sleep for 1 second\n",
    "time.sleep(1)\n",
    "\n",
    "# Return all the HTML on our page\n",
    "html = browser.html\n",
    "\n",
    "######################################################################\n",
    "# grabbing all links to the images on homepage\n",
    "links = browser.find_by_css(\"a.product-item img\")\n",
    "\n",
    "# Create a Beautiful Soup object, pass in our HTML, and call 'html.parser'\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# finding the the title and link of every image\n",
    "for i in range(len(links)):\n",
    "    results = {}\n",
    "\n",
    "    browser.find_by_css(\"a.product-item img\")[i].click()\n",
    "    # link.click()\n",
    "    time.sleep(1)\n",
    "    # appending the scrapped data to the results dictionary\n",
    "    element = browser.links.find_by_text(\"Original\").first\n",
    "    results[\"title\"] = browser.find_by_css(\"h2.title\").text\n",
    "    results[\"img_url\"] = element[\"href\"]\n",
    "    \n",
    "    listings.update(results)\n",
    "\n",
    "    # appening the results dictionary into the img_urls list\n",
    "    #listings.append(results)\n",
    "    browser.back()\n",
    "    time.sleep(1)\n",
    "\n",
    "# Build our dictionary for the headline, price, and neighborhood from our scraped data\n",
    "\n",
    "# Quit the browser\n",
    "#browser.quit()\n",
    "\n",
    "######################################################################\n",
    "######################################################################\n",
    "url = 'https://spaceimages-mars.com/'\n",
    "browser.visit(url)\n",
    "\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "featured_image_link = url + soup.find('img', class_=\"headerimage\")[\"src\"]\n",
    "\n",
    "listings['featured_image'] = featured_image_link\n",
    "######################################################################\n",
    "######################################################################\n",
    "url = \"https://galaxyfacts-mars.com/\"\n",
    "\n",
    "facts_about_mars = pd.read_html(url)\n",
    "\n",
    "mars_facts_df = pd.DataFrame(facts_about_mars)\n",
    "\n",
    "## DataFrames as HTML\n",
    "mars_planet_profile_html = mars_facts_df.to_html()\n",
    "\n",
    "#### removing unwanted newlines to clean up the table.\n",
    "# mars_planet_profile_html.replace('\\n', '')\n",
    "\n",
    "# show table\n",
    "mars_planet_profile_html\n",
    "\n",
    "listings[\"mars_table\"] = mars_planet_profile_html\n",
    "######################################################################\n",
    "######################################################################\n",
    "\n",
    "url = 'https://redplanetscience.com/'\n",
    "browser.visit(url)\n",
    "\n",
    "headlines = []\n",
    "\n",
    "# scrapping the data\n",
    "for x in range(0, 15):\n",
    "    time.sleep(0.1)\n",
    "\n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    titles = soup.findAll(name='div', attrs=\"content_title\")\n",
    "    # for title in titles:\n",
    "    # print(title.text)\n",
    "\n",
    "    results['titles'] = browser.find_by_css(\"div.content_title\")[x].text\n",
    "    results['teaser'] = browser.find_by_css(\"div.article_teaser_body\")[x].text\n",
    "\n",
    "    # for headline, teaser_text in zip (headline_titles, teaser_paragraph):\n",
    "    # results['titles'] = headline.text\n",
    "    # results['teaser'] = teaser_text.text\n",
    "    listings.update(results)\n",
    "    headlines.append(results)\n",
    "    time.sleep(0.1)\n",
    "\n",
    "# browser.quit()\n",
    "######################################################################\n",
    "######################################################################\n",
    "\n",
    "######################################################################\n",
    "\n",
    "# Return our dictionary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06a66ec7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n",
      "INFO:WDM:====== WebDriver manager ======\n",
      "[WDM] - Current google-chrome version is 103.0.5060\n",
      "INFO:WDM:Current google-chrome version is 103.0.5060\n",
      "[WDM] - Get LATEST chromedriver version for 103.0.5060 google-chrome\n",
      "INFO:WDM:Get LATEST chromedriver version for 103.0.5060 google-chrome\n",
      "[WDM] - Driver [/Users/user/.wdm/drivers/chromedriver/mac64/103.0.5060.53/chromedriver] found in cache\n",
      "INFO:WDM:Driver [/Users/user/.wdm/drivers/chromedriver/mac64/103.0.5060.53/chromedriver] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'Cerberus Hemisphere Enhanced', 'img_url': 'https://marshemispheres.com/images/cerberus_enhanced.tif'}, {'title': 'Schiaparelli Hemisphere Enhanced', 'img_url': 'https://marshemispheres.com/images/schiaparelli_enhanced.tif'}, {'title': 'Syrtis Major Hemisphere Enhanced', 'img_url': 'https://marshemispheres.com/images/syrtis_major_enhanced.tif'}, {'title': 'Valles Marineris Hemisphere Enhanced', 'img_url': 'https://marshemispheres.com/images/valles_marineris_enhanced.tif'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/pandas/core/internals/construction.py:540: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  values = np.array([convert(v) for v in values])\n"
     ]
    }
   ],
   "source": [
    "# Setup splinter\n",
    "# browser = init_browser()\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "\n",
    "# Set an empty dict for listings that we can save to Mongo\n",
    "# listings = {\"planet_images\":img_urls}\n",
    "\n",
    "# The url we want to scrape\n",
    "url = \"https://marshemispheres.com/\"\n",
    "\n",
    "# Call visit on our browser and pass in the URL we want to scrape\n",
    "browser.visit(url)\n",
    "\n",
    "# Let it sleep for 1 second\n",
    "time.sleep(1)\n",
    "\n",
    "# Return all the HTML on our page\n",
    "html = browser.html\n",
    "\n",
    "######################################################################\n",
    "\n",
    "# grabbing all links to the images on homepage\n",
    "links = browser.find_by_css(\"a.product-item img\")\n",
    "\n",
    "img_urls = []\n",
    "\n",
    "# finding the the title and link of every image\n",
    "for i in range(len(links)):\n",
    "    marshemispheres = {}\n",
    "\n",
    "    browser.find_by_css(\"a.product-item img\")[i].click()\n",
    "    # link.click()\n",
    "    time.sleep(1)\n",
    "    # appending the scrapped data to the results dictionary\n",
    "    element = browser.links.find_by_text(\"Original\").first\n",
    "    marshemispheres[\"title\"] = browser.find_by_css(\"h2.title\").text\n",
    "    marshemispheres[\"img_url\"] = element[\"href\"]\n",
    "\n",
    "    # appening the results dictionary into the img_urls list\n",
    "    img_urls.append(marshemispheres)\n",
    "    browser.back()\n",
    "    time.sleep(1)\n",
    "# close the browser\n",
    "# browser.quit()\n",
    "print(img_urls)\n",
    "\n",
    "# Build our dictionary for the headline, price, and neighborhood from our scraped data\n",
    "\n",
    "# Quit the browser\n",
    "# browser.quit()\n",
    "\n",
    "######################################################################\n",
    "######################################################################\n",
    "url = 'https://spaceimages-mars.com/'\n",
    "browser.visit(url)\n",
    "\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "featured_image_link = url + soup.find('img', class_=\"headerimage\")[\"src\"]\n",
    "\n",
    "# listings['featured_image'] = featured_image_link\n",
    "######################################################################\n",
    "######################################################################\n",
    "url = \"https://galaxyfacts-mars.com/\"\n",
    "\n",
    "facts_about_mars = pd.read_html(url)\n",
    "\n",
    "mars_facts_df = pd.DataFrame(facts_about_mars)\n",
    "\n",
    "## DataFrames as HTML\n",
    "mars_planet_profile_html = mars_facts_df.to_html()\n",
    "\n",
    "#### removing unwanted newlines to clean up the table.\n",
    "mars_planet_profile_html.replace('\\n', '')\n",
    "\n",
    "# show table\n",
    "mars_planet_profile_html\n",
    "\n",
    "# listings[\"mars_table\"] = mars_planet_profile_html\n",
    "######################################################################\n",
    "######################################################################\n",
    "\n",
    "# browser.quit()\n",
    "######################################################################\n",
    "######################################################################\n",
    "\n",
    "url = 'https://redplanetscience.com/'\n",
    "browser.visit(url)\n",
    "\n",
    "headlines = []\n",
    "\n",
    "# scrapping the data\n",
    "for x in range(0, 15):\n",
    "    time.sleep(1)\n",
    "\n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    redplanet = {}\n",
    "\n",
    "    titles = soup.findAll(name='div', attrs=\"content_title\")\n",
    "    # for title in titles:\n",
    "    # print(title.text)\n",
    "\n",
    "    redplanet['titles'] = browser.find_by_css(\"div.content_title\")[x].text\n",
    "    redplanet['teaser'] = browser.find_by_css(\"div.article_teaser_body\")[x].text\n",
    "\n",
    "    headlines.append(redplanet)\n",
    "\n",
    "    # for headline, teaser_text in zip (headline_titles, teaser_paragraph):\n",
    "    # results['titles'] = headline.text\n",
    "    # results['teaser'] = teaser_text.text\n",
    "\n",
    "    # headlines.append(results)\n",
    "    # time.sleep(2)\n",
    "\n",
    "    # browser.quit()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ######################################################################\n",
    "listings = {\"planet_images\":img_urls,\n",
    "            \"featured_image\":featured_image_link,\n",
    "            \"mars_table\":mars_planet_profile_html,\n",
    "            \"latest_news\":headlines\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01c80fd3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Valles Marineris Hemisphere Enhanced',\n",
       " 'img_url': 'https://marshemispheres.com/images/valles_marineris_enhanced.tif',\n",
       " 'featured_image': 'https://spaceimages-mars.com/image/featured/mars3.jpg',\n",
       " 'mars_table': '<table border=\"1\" class=\"dataframe\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th></th>\\n      <th>0</th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <th>0</th>\\n      <td>0                1                2\\n0  Mars - Earth Comparison             Mars            Earth\\n1                Diameter:         6,779 km        12,742 km\\n2                    Mass:  6.39 × 10^23 kg  5.97 × 10^24 kg\\n3                   Moons:                2                1\\n4       Distance from Sun:   227,943,824 km   149,598,262 km\\n5          Length of Year:   687 Earth days      365.24 days\\n6             Temperature:     -87 to -5 °C      -88 to 58°C</td>\\n    </tr>\\n    <tr>\\n      <th>1</th>\\n      <td>0                              1\\n0  Equatorial Diameter:                       6,792 km\\n1       Polar Diameter:                       6,752 km\\n2                 Mass:  6.39 × 10^23 kg (0.11 Earths)\\n3                Moons:          2 ( Phobos &amp; Deimos )\\n4       Orbit Distance:       227,943,824 km (1.38 AU)\\n5         Orbit Period:           687 days (1.9 years)\\n6  Surface Temperature:                   -87 to -5 °C\\n7         First Record:              2nd millennium BC\\n8          Recorded By:           Egyptian astronomers</td>\\n    </tr>\\n  </tbody>\\n</table>',\n",
       " 'titles': \"NASA's Curiosity Mars Rover Snaps Its Highest-Resolution Panorama Yet\",\n",
       " 'teaser': 'To go along with the stunning 1.8-billion-pixel image, a new video offers a sweeping view of the Red Planet.'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf22dc34",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "https://spaceimages-mars.com/image/featured/mars1.jpg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
